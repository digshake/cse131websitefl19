---
name: k Nearest Neighbors
week: 7
number: 4
points: 4
---

Authors

: Brandon Mendez

## Overview

This assignment incorporates principles of <a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank">
Machine learning</a>, which is an area of study in computer science that falls within the larger area of study known as artificial intelligence. Here, we are trying to <EM>teach</EM> a computer to reason about a problem based on data we provide.

One such simple task to consider is learning the value of a function at some position in two-dimensional (say, x and y) space. The value of this function may not have an obvious relationship with its x or y coordinates. Moreover, we can't use linear regression to represent the function by a line, because the function's values depend on two inputs. We could try to generalize linear regression to use a plane to represent this function.  Unfortunately, the problem we consider here is not amenable to accurate representation using a plane, but the data does possess one feature that suggests using a particular approach to approximate the function's values.

The data we consider here is literally comprised of neighborhoods, such that points within a physical neighborhoods behave similarly.  For the sake of this problem, we do not know the physical boundaries of any neighborhood. However, if we can impose neighborhoods of our own choosing over the data and use those implied neighborhoods to approximate the value of point within that neighborhood.

In particular, we can approximate a position's value using this sample data by taking the k nearest points (neighbors) to the position of interest and averaging the neighbors' values, where k is an integer greater than 0. 

For any chosen value of k and any position of interest, that position's k nearest neighbors occur within some radius from the position. The value of k thus determines the circular neighborhood imposed at the position of interest, with the assumption that points within that circular area behave similarly.  Where known data points are dense, the radius will be smaller;  where known data points are sparse, the radius is adaptively larger, so that in any computation, k points participate in determining the value at a position of interest.

But what exactly should k be? How many points must be provided to learn the implied value?   As an example, consider computing some aspect of the weather (temperature, wind speed, etc.) at a point of interest based on averaging the aspect's value at the k neighbors nearest to the point of interest.  If k is too large, then we will be computing an average value that holds over a large area, but probably does not hold at the specific point of interest.  If k is too small, we may not have enough data to compute the point's value accurately.

Thus, the choice of k is itself of interest in solving this problem.

In this assignment we consider the location of a house (its position in space) and that house's cost (its value). If we assume that these two properties are related, then we should
be able to predict the sales price of a house in any location by analyzing some actual examples of sales prices for houses and the location (latitude and longitude) of those houses.

The simple example of machine learning that we study here is called <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" target="_blank">k Nearest Neighbors</a>. This technique allows us to take many data points with two known variables, plot them, and then predict the value of one variable when given the other. In this assignment you will approximate the values of hypothetical homes given the actual selling prices and locations of thousands of houses in the <a href="https://en.wikipedia.org/wiki/Broward_County,_Florida" target="_blank">Broward County, Florida</a> area. When your algorithm reads the given data, you can predict the price of a house at any location.

## Procedure

<OL>
<LI>In your repository, find the <kbd>neighbors</kbd> package. You will write your code in the <kbd>kNearestNeighbors</kbd> class.
<LI>Finish the code for the <kbd>predictPrice()</kbd> method. 
<UL>
 <LI> This method takes in the x and y positions of a hypothetical home, along with an array containing the price, x, and y locations of actual homes. It also takes in a value for <kbd>k</kbd> so that we can test your code in different situations. Your method needs to be able to:</LI>
  <UL>
   <LI> Calculate the distance of the house in question to each of the actual homes.</LI>
   <LI> Use those distances to find the <kbd>k</kbd> nearest homes to the given house.</LI>
   <LI> Average the values of those <kbd>k</kbd> nearest homes to predict the price of the house we are looking for.</LI>
  </UL>
</UL>
<LI>Once you finish implementing the algorithm, you can run NeighborhoodGraph to see it in action. This draws a real map of Broward County, with the housing data points on top of it. You can see that as houses get more expensive they show up as darker red, and as they get more affordable they show as a lighter yellow. If you click on the map, your prediction will show up in the Eclipse console. Make sure each area on the map corresponds to the appropriate price range relative to the other areas. If you are getting inconsistent results, make sure you are calculating distance properly, and storing the prices of the closest houses properly as well.
<LI>Make sure that your code passes the testPrediction Unit test in the TestNeighbors class.
<LI> Demo your results to a TA to receive credit.